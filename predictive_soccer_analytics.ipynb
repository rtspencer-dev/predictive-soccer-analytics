{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPuD6VvRumGj3PbQtG2X0lZ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "f3feGx5zNTSZ"
      },
      "outputs": [],
      "source": [
        "# IMPORT NECESSARY LIBRARIES\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# scipy?\n",
        "# sklearn?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MOUNT GOOGLE DRIVE\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFdcyE6dN4oD",
        "outputId": "f0dc7a56-c9d6-481a-acb0-0f82146cf257"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Data Cleaning"
      ],
      "metadata": {
        "id": "hh8-rZvEOExE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BASE DATASET PATH\n",
        "DATA_DIR = Path(\"/content/drive/MyDrive/Datasets/big-five-football-xg-data/\")\n",
        "\n",
        "# LOAD & COMBINE ALL CSV FILES\n",
        "def load_raw_data(csv_dir):\n",
        "    csv_dir = Path(csv_dir)\n",
        "    dfs = [pd.read_csv(f) for f in csv_dir.glob(\"*.csv\")]\n",
        "    df = pd.concat(dfs, ignore_index=True)\n",
        "    return df\n",
        "\n",
        "# STANDARDIZE COLUMN NAMES\n",
        "def standardize_columns(df):\n",
        "    df.columns = (\n",
        "        df.columns\n",
        "        .str.strip()\n",
        "        .str.lower()\n",
        "        .str.replace(\" \", \"_\")\n",
        "    )\n",
        "    return df\n",
        "\n",
        "# PARSE DATETIME SAFELY\n",
        "def parse_datetime(df):\n",
        "    df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
        "    df[\"time\"] = df[\"time\"].astype(str).str.zfill(5)\n",
        "    df[\"datetime\"] = pd.to_datetime(\n",
        "        df[\"date\"].astype(str) + \" \" + df[\"time\"],\n",
        "        errors=\"coerce\"\n",
        "    )\n",
        "    return df\n",
        "\n",
        "# CLEAN xG COLUMNS\n",
        "def clean_xg(df):\n",
        "    for col in [\"xg_home\", \"xg_away\"]:\n",
        "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "        # xG sanity bounds\n",
        "        df.loc[df[col] < 0, col] = np.nan\n",
        "        df.loc[df[col] > 6, col] = np.nan\n",
        "    return df\n",
        "\n",
        "# PARSE SCORE INTO GOALS\n",
        "def parse_score(df):\n",
        "    df[\"score\"] = (\n",
        "        df[\"score\"]\n",
        "        .astype(str)\n",
        "        .str.replace(\"–\", \"-\", regex=False)\n",
        "        .str.replace(\"—\", \"-\", regex=False)\n",
        "    )\n",
        "    goals = df[\"score\"].str.split(\"-\", expand=True)\n",
        "    df[\"home_goals\"] = pd.to_numeric(goals[0], errors=\"coerce\")\n",
        "    df[\"away_goals\"] = pd.to_numeric(goals[1], errors=\"coerce\")\n",
        "    return df\n",
        "\n",
        "# CLEAN TEAM NAMES\n",
        "def clean_team_names(df):\n",
        "    for col in [\"home\", \"away\"]:\n",
        "        df[col] = (\n",
        "            df[col]\n",
        "            .astype(str)\n",
        "            .str.strip()\n",
        "        )\n",
        "    return df\n",
        "\n",
        "# REMOVE DUPLICATES\n",
        "def remove_duplicates(df):\n",
        "    df = df.drop_duplicates(\n",
        "        subset=[\"datetime\", \"home\", \"away\"]\n",
        "    )\n",
        "    return df\n",
        "\n",
        "# DROP INDEX COLUMNS\n",
        "def drop_index_columns(df):\n",
        "    index_cols = [c for c in df.columns if c.startswith(\"unnamed\")]\n",
        "    return df.drop(columns=index_cols)\n",
        "\n",
        "# LOGICAL VALIDATION\n",
        "def validate_rows(df):\n",
        "    conditions = (\n",
        "        df[\"datetime\"].notna() &\n",
        "        df[\"home\"].notna() &\n",
        "        df[\"away\"].notna() &\n",
        "        df[\"xg_home\"].notna() &\n",
        "        df[\"xg_away\"].notna() &\n",
        "        df[\"home_goals\"].notna() &\n",
        "        df[\"away_goals\"].notna()\n",
        "    )\n",
        "    df = df.loc[conditions].copy()\n",
        "    return df\n",
        "\n",
        "# FINAL CLEANING PIPELINE\n",
        "def clean_match_data(csv_dir):\n",
        "    df = load_raw_data(csv_dir)\n",
        "    df = standardize_columns(df)\n",
        "    df = parse_datetime(df)\n",
        "    df = clean_xg(df)\n",
        "    df = parse_score(df)\n",
        "    df = clean_team_names(df)\n",
        "    df = remove_duplicates(df)\n",
        "    df = drop_index_columns(df)\n",
        "    df = validate_rows(df)\n",
        "    # Sort chronologically (CRITICAL)\n",
        "    df = df.sort_values(\"datetime\").reset_index(drop=True)\n",
        "    return df"
      ],
      "metadata": {
        "id": "JjUtjJMjOK-7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SAVE CLEANED DATA\n",
        "df_clean = clean_match_data(DATA_DIR)\n",
        "\n",
        "OUTPUT_DIR = Path(\"/content/drive/MyDrive/Datasets/big-five-football-xg-data/processed/\")\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "clean_path = OUTPUT_DIR / \"matches_cleaned.csv\"\n",
        "df_clean.to_csv(clean_path, index=False)\n",
        "\n",
        "print(f\"Saved cleaned data to: {clean_path}\")\n",
        "print(f\"Rows: {len(df_clean)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxSMJ5KcYxnU",
        "outputId": "faf6b864-d94a-4446-b4a9-aed9e422b291"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved cleaned data to: /content/drive/MyDrive/Datasets/big-five-football-xg-data/processed/matches_cleaned.csv\n",
            "Rows: 9034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Feature Engineering"
      ],
      "metadata": {
        "id": "0L8MgZ4CYiju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD CLEANED DATA\n",
        "df_clean = pd.read_csv(\n",
        "    clean_path,\n",
        "    parse_dates=[\"datetime\"]\n",
        ")\n",
        "\n",
        "EPSILON = 1e-6\n",
        "\n",
        "# MATCH ID\n",
        "def add_match_id(df):\n",
        "    df[\"match_id\"] = (\n",
        "        df[\"home\"] + \"_vs_\" + df[\"away\"] + \"_\" +\n",
        "        df[\"datetime\"].dt.strftime(\"%Y%m%d_%H%M\")\n",
        "    )\n",
        "    return df\n",
        "\n",
        "# TARGET VARIABLE\n",
        "def create_target(df):\n",
        "    df = df.copy()\n",
        "    df[\"result\"] = np.select(\n",
        "    [\n",
        "        df[\"home_goals\"] > df[\"away_goals\"],\n",
        "        df[\"home_goals\"] == df[\"away_goals\"],\n",
        "        df[\"home_goals\"] < df[\"away_goals\"]\n",
        "    ],\n",
        "    [\"home_win\", \"draw\", \"away_win\"],\n",
        "    default=\"unknown\"\n",
        "    )\n",
        "    return df\n",
        "\n",
        "# CORE xG FEATURES\n",
        "def core_xg_features(df):\n",
        "    df = df.copy()\n",
        "    df[\"xg_diff\"] = df[\"xg_home\"] - df[\"xg_away\"]\n",
        "    df[\"total_xg\"] = df[\"xg_home\"] + df[\"xg_away\"]\n",
        "    df[\"home_xg_share\"] = df[\"xg_home\"] / (df[\"total_xg\"] + EPSILON)\n",
        "    df[\"xg_ratio\"] = df[\"xg_home\"] / (df[\"xg_away\"] + EPSILON)\n",
        "    return df\n",
        "\n",
        "# FEATURE PIPELINE\n",
        "def build_features(df):\n",
        "    df = add_match_id(df)\n",
        "    df = create_target(df)\n",
        "    df = core_xg_features(df)\n",
        "    df = df.dropna().reset_index(drop=True)\n",
        "    return df"
      ],
      "metadata": {
        "id": "-EY_k6I4YhTQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SAVE FEATURES\n",
        "INPUT_PATH = Path(\"/content/drive/MyDrive/Datasets/big-five-football-xg-data/processed/matches_cleaned.csv\")\n",
        "OUTPUT_PATH = Path(\"/content/drive/MyDrive/Datasets/big-five-football-xg-data/processed/matches_features.csv\")\n",
        "\n",
        "df_clean = pd.read_csv(INPUT_PATH, parse_dates=[\"datetime\"])\n",
        "df_features = build_features(df_clean)\n",
        "\n",
        "df_features.to_csv(OUTPUT_PATH, index=False)\n",
        "\n",
        "print(f\"Saved feature dataset to: {OUTPUT_PATH}\")\n",
        "print(f\"Rows: {len(df_features)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dil8lL_6iYY-",
        "outputId": "c17aa193-4a03-4463-d4c0-9f0cd11b3fc7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved feature dataset to: /content/drive/MyDrive/Datasets/big-five-football-xg-data/processed/matches_features.csv\n",
            "Rows: 2288\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Modeling and Evaluation"
      ],
      "metadata": {
        "id": "d4_xGhhxmKCl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Preparation"
      ],
      "metadata": {
        "id": "ZVa7g8DrnMV9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of columns to drop from features\n",
        "drop_cols = ['datetime', 'day', 'date', 'time', 'score', 'home', 'away', 'match_id', 'home_goals', 'away_goals', 'result', 'attendance', 'venue', 'referee', 'round']\n",
        "\n",
        "# Features (X)\n",
        "X = df_features.drop(columns=drop_cols)\n",
        "\n",
        "# Target (y)\n",
        "y = df_features['result']\n",
        "\n",
        "# Assume df_features has a 'datetime' column\n",
        "train_cutoff = '2021-08-01' # All matches before this date go into training\n",
        "\n",
        "X_train = X[df_features['datetime'] < train_cutoff]\n",
        "X_test = X[df_features['datetime'] >= train_cutoff]\n",
        "\n",
        "y_train = y[df_features['datetime'] < train_cutoff]\n",
        "y_test = y[df_features['datetime'] >= train_cutoff]\n",
        "\n",
        "# Training/Testing Split\n",
        "print(\"Training matches:\", len(X_train))\n",
        "print(\"Testing matches:\", len(X_test))\n",
        "print(\"Training date range:\", df_features['datetime'].min(), \"to\", df_features['datetime'][df_features['datetime'] < train_cutoff].max())\n",
        "print(\"Testing date range:\", df_features['datetime'][df_features['datetime'] >= train_cutoff].min(), \"to\", df_features['datetime'].max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3RTg-nCmM8i",
        "outputId": "0567e52d-dd1f-4002-c3e3-6331b2e4e675"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training matches: 1633\n",
            "Testing matches: 655\n",
            "Training date range: 2017-08-04 20:45:00 to 2021-05-22 15:30:00\n",
            "Testing date range: 2021-08-06 21:00:00 to 2022-05-21 21:00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SCALING\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "urlPdi4xpmkM"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Logistic Regression"
      ],
      "metadata": {
        "id": "THbsg9G8rk-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SUSjPo65roCy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
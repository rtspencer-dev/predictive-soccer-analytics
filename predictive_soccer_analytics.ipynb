{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEHquDjx6SZZ5soqH6fsF4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "f3feGx5zNTSZ"
      },
      "outputs": [],
      "source": [
        "# IMPORT NECESSARY LIBRARIES\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from clean_data import clean_match_data\n",
        "from google.colab import drive\n",
        "# scipy?\n",
        "# sklearn?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MOUNT GOOGLE DRIVE\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFdcyE6dN4oD",
        "outputId": "effedeaa-8f32-49b4-cf79-008efb17e9bc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Data Cleaning"
      ],
      "metadata": {
        "id": "hh8-rZvEOExE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BASE DATASET PATH\n",
        "DATA_DIR = Path(\"/content/drive/MyDrive/Datasets/big-five-football-xg-data/\")\n",
        "\n",
        "# LOAD & COMBINE ALL CSV FILES\n",
        "def load_raw_data(csv_dir):\n",
        "    csv_dir = Path(csv_dir)\n",
        "    dfs = [pd.read_csv(f) for f in csv_dir.glob(\"*.csv\")]\n",
        "    df = pd.concat(dfs, ignore_index=True)\n",
        "    return df\n",
        "\n",
        "# STANDARDIZE COLUMN NAMES\n",
        "def standardize_columns(df):\n",
        "    df.columns = (\n",
        "        df.columns\n",
        "        .str.strip()\n",
        "        .str.lower()\n",
        "        .str.replace(\" \", \"_\")\n",
        "    )\n",
        "    return df\n",
        "\n",
        "# PARSE DATETIME SAFELY\n",
        "def parse_datetime(df):\n",
        "    df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
        "    df[\"time\"] = df[\"time\"].astype(str).str.zfill(5)\n",
        "    df[\"datetime\"] = pd.to_datetime(\n",
        "        df[\"date\"].astype(str) + \" \" + df[\"time\"],\n",
        "        errors=\"coerce\"\n",
        "    )\n",
        "    return df\n",
        "\n",
        "# CLEAN xG COLUMNS\n",
        "def clean_xg(df):\n",
        "    for col in [\"xg_home\", \"xg_away\"]:\n",
        "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "        # xG sanity bounds\n",
        "        df.loc[df[col] < 0, col] = np.nan\n",
        "        df.loc[df[col] > 6, col] = np.nan\n",
        "    return df\n",
        "\n",
        "# PARSE SCORE INTO GOALS\n",
        "def parse_score(df):\n",
        "    df[\"score\"] = (\n",
        "        df[\"score\"]\n",
        "        .astype(str)\n",
        "        .str.replace(\"–\", \"-\", regex=False)\n",
        "        .str.replace(\"—\", \"-\", regex=False)\n",
        "    )\n",
        "    goals = df[\"score\"].str.split(\"-\", expand=True)\n",
        "    df[\"home_goals\"] = pd.to_numeric(goals[0], errors=\"coerce\")\n",
        "    df[\"away_goals\"] = pd.to_numeric(goals[1], errors=\"coerce\")\n",
        "    return df\n",
        "\n",
        "# CLEAN TEAM NAMES\n",
        "def clean_team_names(df):\n",
        "    for col in [\"home\", \"away\"]:\n",
        "        df[col] = (\n",
        "            df[col]\n",
        "            .astype(str)\n",
        "            .str.strip()\n",
        "        )\n",
        "    return df\n",
        "\n",
        "# REMOVE DUPLICATES\n",
        "def remove_duplicates(df):\n",
        "    df = df.drop_duplicates(\n",
        "        subset=[\"datetime\", \"home\", \"away\"]\n",
        "    )\n",
        "    return df\n",
        "\n",
        "# DROP INDEX COLUMNS\n",
        "def drop_index_columns(df):\n",
        "    index_cols = [c for c in df.columns if c.startswith(\"unnamed\")]\n",
        "    return df.drop(columns=index_cols)\n",
        "\n",
        "# LOGICAL VALIDATION\n",
        "def validate_rows(df):\n",
        "    conditions = (\n",
        "        df[\"datetime\"].notna() &\n",
        "        df[\"home\"].notna() &\n",
        "        df[\"away\"].notna() &\n",
        "        df[\"xg_home\"].notna() &\n",
        "        df[\"xg_away\"].notna() &\n",
        "        df[\"home_goals\"].notna() &\n",
        "        df[\"away_goals\"].notna()\n",
        "    )\n",
        "    df = df.loc[conditions].copy()\n",
        "    return df\n",
        "\n",
        "# FINAL CLEANING PIPELINE\n",
        "def clean_match_data(csv_dir):\n",
        "    df = load_raw_data(csv_dir)\n",
        "    df = standardize_columns(df)\n",
        "    df = parse_datetime(df)\n",
        "    df = clean_xg(df)\n",
        "    df = parse_score(df)\n",
        "    df = clean_team_names(df)\n",
        "    df = remove_duplicates(df)\n",
        "    df = drop_index_columns(df)\n",
        "    df = validate_rows(df)\n",
        "    # Sort chronologically (CRITICAL)\n",
        "    df = df.sort_values(\"datetime\").reset_index(drop=True)\n",
        "    return df"
      ],
      "metadata": {
        "id": "JjUtjJMjOK-7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SAVE CLEANED DATA\n",
        "df_clean = clean_match_data(DATA_DIR)\n",
        "\n",
        "OUTPUT_DIR = Path(\"/content/drive/MyDrive/Datasets/big-five-football-xg-data/processed/\")\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "clean_path = OUTPUT_DIR / \"matches_cleaned.csv\"\n",
        "df_clean.to_csv(clean_path, index=False)\n",
        "\n",
        "print(f\"Saved cleaned data to: {clean_path}\")\n",
        "print(f\"Rows: {len(df_clean)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxSMJ5KcYxnU",
        "outputId": "419d3ec1-d179-40e3-f517-10593456adb4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved cleaned data to: /content/drive/MyDrive/Datasets/big-five-football-xg-data/processed/matches_cleaned.csv\n",
            "Rows: 9034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Feature Engineering"
      ],
      "metadata": {
        "id": "0L8MgZ4CYiju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD CLEANED DATA\n",
        "df_clean = pd.read_csv(\n",
        "    clean_path,\n",
        "    parse_dates=[\"datetime\"]\n",
        ")\n"
      ],
      "metadata": {
        "id": "-EY_k6I4YhTQ"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}